{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yxvzFnySHdqd"
   },
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59591,
     "status": "ok",
     "timestamp": 1570466005216,
     "user": {
      "displayName": "Dimitre Oliveira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBHzrYFhikwGj5HS4HCH2B5iUmYoPpm1AFV6OcFBA=s64",
      "userId": "06256612867315483887"
     },
     "user_tz": 180
    },
    "hide_input": false,
    "id": "cG_j8ky3Hdqk",
    "outputId": "86a41fc1-4f09-4403-9a3c-b7133a844fd7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\program files\\python36\\lib\\site-packages\\classification_models\\resnext\\__init__.py:4: UserWarning: Current ResNext models are deprecated, use keras.applications ResNeXt models\n",
      "  warnings.warn('Current ResNext models are deprecated, '\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from skimage import exposure\n",
    "import multiprocessing as mp\n",
    "import albumentations as albu\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import set_random_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from keras import backend as K\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Input, average\n",
    "from keras import optimizers, applications\n",
    "from keras.models import Model, load_model\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Required repositories\n",
    "os.system('pip install segmentation-models')\n",
    "os.system('pip install keras-rectified-adam')\n",
    "os.system('pip install tta-wrapper')\n",
    "\n",
    "from keras_radam import RAdam\n",
    "import segmentation_models as sm\n",
    "from tta_wrapper import tta_segmentation\n",
    "\n",
    "# Misc\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    set_random_seed(seed)\n",
    "    \n",
    "    \n",
    "# Segmentation related\n",
    "def rle_decode(mask_rle, shape=(1400, 2100)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape, order='F')  # Needed to align to RLE direction\n",
    "\n",
    "def rle_to_mask(rle_string, height, width):\n",
    "    rows, cols = height, width\n",
    "    \n",
    "    if rle_string == -1:\n",
    "        return np.zeros((height, width))\n",
    "    else:\n",
    "        rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n",
    "        rle_pairs = np.array(rle_numbers).reshape(-1,2)\n",
    "        img = np.zeros(rows*cols, dtype=np.uint8)\n",
    "        for index, length in rle_pairs:\n",
    "            index -= 1\n",
    "            img[index:index+length] = 255\n",
    "        img = img.reshape(cols,rows)\n",
    "        img = img.T\n",
    "        return img\n",
    "    \n",
    "def get_mask_area(df, index, column_name, shape=(1400, 2100)):\n",
    "    rle = df.loc[index][column_name]\n",
    "    try:\n",
    "        math.isnan(rle)\n",
    "        np_mask = np.zeros((shape[0], shape[1], 3))\n",
    "    except:\n",
    "        np_mask = rle_to_mask(rle, shape[0], shape[1])\n",
    "        np_mask = np.clip(np_mask, 0, 1)\n",
    "        \n",
    "    return int(np.sum(np_mask))\n",
    "\n",
    "def np_resize(img, input_shape):\n",
    "    \"\"\"\n",
    "    Reshape a numpy array, which is input_shape=(height, width), \n",
    "    as opposed to input_shape=(width, height) for cv2\n",
    "    \"\"\"\n",
    "    height, width = input_shape\n",
    "    return cv2.resize(img, (width, height))\n",
    "    \n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def build_rles(masks, reshape=None):\n",
    "    width, height, depth = masks.shape\n",
    "    rles = []\n",
    "    \n",
    "    for i in range(depth):\n",
    "        mask = masks[:, :, i]\n",
    "        \n",
    "        if reshape:\n",
    "            mask = mask.astype(np.float32)\n",
    "            mask = np_resize(mask, reshape).astype(np.int64)\n",
    "        \n",
    "        rle = mask2rle(mask)\n",
    "        rles.append(rle)\n",
    "        \n",
    "    return rles\n",
    "\n",
    "def build_masks(rles, input_shape, reshape=None):\n",
    "    depth = len(rles)\n",
    "    if reshape is None:\n",
    "        masks = np.zeros((*input_shape, depth))\n",
    "    else:\n",
    "        masks = np.zeros((*reshape, depth))\n",
    "    \n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            if reshape is None:\n",
    "                masks[:, :, i] = rle2mask(rle, input_shape)\n",
    "            else:\n",
    "                mask = rle2mask(rle, input_shape)\n",
    "                reshaped_mask = np_resize(mask, reshape)\n",
    "                masks[:, :, i] = reshaped_mask\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def rle2mask(rle, input_shape):\n",
    "    width, height = input_shape[:2]\n",
    "    mask = np.zeros( width*height ).astype(np.uint8)\n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = 1\n",
    "        current_position += lengths[index]\n",
    "        \n",
    "    return mask.reshape(height, width).T\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).astype(np.bool)\n",
    "    y_pred = np.asarray(y_pred).astype(np.bool)\n",
    "    intersection = np.logical_and(y_true, y_pred)\n",
    "    return (2. * intersection.sum()) / (y_true.sum() + y_pred.sum())\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    \n",
    "# Data pre-process\n",
    "def preprocess_image(image_id, base_path, save_path, HEIGHT, WIDTH):\n",
    "    image = cv2.imread(base_path + image_id)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (WIDTH, HEIGHT))\n",
    "    cv2.imwrite(save_path + image_id, image)\n",
    "    \n",
    "def pre_process_set(df, preprocess_fn):\n",
    "    n_cpu = mp.cpu_count()\n",
    "    df_n_cnt = df.shape[0]//n_cpu\n",
    "    pool = mp.Pool(n_cpu)\n",
    "    \n",
    "    dfs = [df.iloc[df_n_cnt*i:df_n_cnt*(i+1)] for i in range(n_cpu)]\n",
    "    dfs[-1] = df.iloc[df_n_cnt*(n_cpu-1):]\n",
    "    res = pool.map(preprocess_fn, [x_df for x_df in dfs])\n",
    "    pool.close()\n",
    "        \n",
    "# def preprocess_data(df, HEIGHT=HEIGHT, WIDTH=WIDTH):\n",
    "#     df = df.reset_index()\n",
    "#     for i in range(df.shape[0]):\n",
    "#         item = df.iloc[i]\n",
    "#         image_id = item['image']\n",
    "#         item_set = item['set']\n",
    "#         if item_set == 'train':\n",
    "#             preprocess_image(image_id, train_base_path, train_images_dest_path, HEIGHT, WIDTH)\n",
    "#         if item_set == 'validation':\n",
    "#             preprocess_image(image_id, train_base_path, validation_images_dest_path, HEIGHT, WIDTH)\n",
    "#         if item_set == 'test':\n",
    "#             preprocess_image(image_id, test_base_path, test_images_dest_path, HEIGHT, WIDTH)\n",
    "\n",
    "# Model evaluation\n",
    "def get_metrics_classification(df, preds, label_columns, threshold=0.5, show_report=True):\n",
    "  accuracy = []\n",
    "  precision = []\n",
    "  recall = []\n",
    "  f_score = []\n",
    "  for index, label in enumerate(label_columns):\n",
    "    print('Metrics for: %s' % label)\n",
    "    if show_report:\n",
    "      print(classification_report(df[label], (preds[:,index] > threshold).astype(int), output_dict=False))\n",
    "    metrics = classification_report(df[label], (preds[:,index] > threshold).astype(int), output_dict=True)\n",
    "    accuracy.append(metrics['accuracy'])\n",
    "    precision.append(metrics['1']['precision'])\n",
    "    recall.append(metrics['1']['recall'])\n",
    "    f_score.append(metrics['1']['f1-score'])\n",
    "    \n",
    "  print('Averaged accuracy:  %.2f' % np.mean(accuracy))\n",
    "  print('Averaged precision: %.2f' % np.mean(precision))\n",
    "  print('Averaged recall:    %.2f' % np.mean(recall))\n",
    "  print('Averaged f_score:   %.2f' % np.mean(f_score))\n",
    "\n",
    "def plot_metrics(history, metric_list=['loss', 'dice_coef'], figsize=(22, 14)):\n",
    "    fig, axes = plt.subplots(len(metric_list), 1, sharex='col', figsize=(22, len(metric_list)*4))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for index, metric in enumerate(metric_list):\n",
    "        axes[index].plot(history[metric], label='Train %s' % metric)\n",
    "        axes[index].plot(history['val_%s' % metric], label='Validation %s' % metric)\n",
    "        axes[index].legend(loc='best')\n",
    "        axes[index].set_title(metric)\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "# Model post process\n",
    "def post_process(probability, threshold=0.5, min_size=10000):\n",
    "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros(probability.shape, np.float32)\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "    return predictions\n",
    "\n",
    "# Prediction evaluation\n",
    "def get_metrics(model, target_df, df, df_images_dest_path, label_columns, tresholds, min_mask_sizes, N_CLASSES=4, seed=0, preprocessing=None, adjust_fn=None, adjust_param=None, set_name='Complete set', column_names=['Class', 'Dice', 'Dice Post']):\n",
    "    metrics = []\n",
    "\n",
    "    for class_name in label_columns:\n",
    "        metrics.append([class_name, 0, 0])\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics, columns=column_names)\n",
    "    \n",
    "    for i in range(0, df.shape[0], 500):\n",
    "        batch_idx = list(range(i, min(df.shape[0], i + 500)))\n",
    "        batch_set = df[batch_idx[0]: batch_idx[-1]+1]\n",
    "        ratio = len(batch_set) / len(df)\n",
    "\n",
    "        generator = DataGenerator(\n",
    "                      directory=df_images_dest_path,\n",
    "                      dataframe=batch_set,\n",
    "                      target_df=target_df,\n",
    "                      batch_size=len(batch_set), \n",
    "                      target_size=model.input_shape[1:3],\n",
    "                      n_channels=model.input_shape[3],\n",
    "                      n_classes=N_CLASSES,\n",
    "                      preprocessing=preprocessing,\n",
    "                      adjust_fn=adjust_fn,\n",
    "                      adjust_param=adjust_param,\n",
    "                      seed=seed,\n",
    "                      mode='fit',\n",
    "                      shuffle=False)\n",
    "\n",
    "        x, y = generator.__getitem__(0)\n",
    "        preds = model.predict(x)\n",
    "        \n",
    "        for class_index in range(N_CLASSES):\n",
    "            class_score = []\n",
    "            class_score_post = []\n",
    "            mask_class = y[..., class_index]\n",
    "            pred_class = preds[..., class_index]\n",
    "            for index in range(len(batch_idx)):\n",
    "                sample_mask = mask_class[index, ]\n",
    "                sample_pred = pred_class[index, ]\n",
    "                sample_pred_post = post_process(sample_pred, threshold=tresholds[class_index], min_size=min_mask_sizes[class_index])\n",
    "                if (sample_mask.sum() == 0) & (sample_pred.sum() == 0):\n",
    "                    dice_score = 1.\n",
    "                else:\n",
    "                    dice_score = dice_coefficient(sample_pred, sample_mask)\n",
    "                if (sample_mask.sum() == 0) & (sample_pred_post.sum() == 0):\n",
    "                    dice_score_post = 1.\n",
    "                else:\n",
    "                    dice_score_post = dice_coefficient(sample_pred_post, sample_mask)\n",
    "                class_score.append(dice_score)\n",
    "                class_score_post.append(dice_score_post)\n",
    "            metrics_df.loc[metrics_df[column_names[0]] == label_columns[class_index], column_names[1]] += np.mean(class_score) * ratio\n",
    "            metrics_df.loc[metrics_df[column_names[0]] == label_columns[class_index], column_names[2]] += np.mean(class_score_post) * ratio\n",
    "\n",
    "    metrics_df = metrics_df.append({column_names[0]:set_name, column_names[1]:np.mean(metrics_df[column_names[1]].values), column_names[2]:np.mean(metrics_df[column_names[2]].values)}, ignore_index=True).set_index(column_names[0])\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "def inspect_predictions(df, image_ids, images_dest_path, pred_col=None, label_col='EncodedPixels', title_col='Image_Label', img_shape=(525, 350), figsize=(22, 6)):\n",
    "    if pred_col:\n",
    "        for sample in image_ids:\n",
    "            sample_df = df[df['image'] == sample]\n",
    "            fig, axes = plt.subplots(2, 5, figsize=figsize)\n",
    "            img = cv2.imread(images_dest_path + sample_df['image'].values[0])\n",
    "            img = cv2.resize(img, img_shape)\n",
    "            axes[0][0].imshow(img)\n",
    "            axes[1][0].imshow(img)\n",
    "            axes[0][0].set_title('Label', fontsize=16)\n",
    "            axes[1][0].set_title('Predicted', fontsize=16)\n",
    "            axes[0][0].axis('off')\n",
    "            axes[1][0].axis('off')\n",
    "            for i in range(4):\n",
    "                mask = sample_df[label_col].values[i]\n",
    "                try:\n",
    "                    math.isnan(mask)\n",
    "                    mask = np.zeros((img_shape[1], img_shape[0]))\n",
    "                except:\n",
    "                    mask = rle_decode(mask)\n",
    "                axes[0][i+1].imshow(mask)\n",
    "                axes[1][i+1].imshow(rle2mask(sample_df[pred_col].values[i], img.shape))\n",
    "                axes[0][i+1].set_title(sample_df[title_col].values[i], fontsize=18)\n",
    "                axes[1][i+1].set_title(sample_df[title_col].values[i], fontsize=18)\n",
    "                axes[0][i+1].axis('off')\n",
    "                axes[1][i+1].axis('off')\n",
    "    else:\n",
    "        for sample in image_ids:\n",
    "            sample_df = df[df['image'] == sample]\n",
    "            fig, axes = plt.subplots(1, 5, figsize=figsize)\n",
    "            img = cv2.imread(images_dest_path + sample_df['image'].values[0])\n",
    "            img = cv2.resize(img, img_shape)\n",
    "            axes[0].imshow(img)\n",
    "            axes[0].set_title('Original', fontsize=16)\n",
    "            axes[0].axis('off')\n",
    "            for i in range(4):\n",
    "                mask = sample_df[label_col].values[i]\n",
    "                try:\n",
    "                    math.isnan(mask)\n",
    "                    mask = np.zeros((img_shape[1], img_shape[0]))\n",
    "                except:\n",
    "                    mask = rle_decode(mask, shape=(img_shape[1], img_shape[0]))\n",
    "                axes[i+1].imshow(mask)\n",
    "                axes[i+1].set_title(sample_df[title_col].values[i], fontsize=18)\n",
    "                axes[i+1].axis('off')\n",
    "                \n",
    "# Model tunning\n",
    "def classification_tunning(y_true, y_pred, label_columns, threshold_grid=np.arange(0, 1, .01), column_names=['Class', 'Threshold', 'Score'], print_score=True):\n",
    "  metrics = []\n",
    "  for label in label_columns:\n",
    "      for threshold in threshold_grid:\n",
    "          metrics.append([label, threshold, 0])\n",
    "\n",
    "  metrics_df = pd.DataFrame(metrics, columns=column_names)\n",
    "  for index, label in enumerate(label_columns):\n",
    "      for thr in threshold_grid:\n",
    "          metrics_df.loc[(metrics_df[column_names[0]] == label) & (metrics_df[column_names[1]] == thr) , column_names[2]] = accuracy_score(y_true[:,index], (y_pred[:,index] > thr).astype(int))\n",
    "\n",
    "  best_tresholds = []\n",
    "  best_scores = []\n",
    "  for index, label in enumerate(label_columns):\n",
    "    metrics_df_lbl = metrics_df[metrics_df[column_names[0]] == label_columns[index]]\n",
    "    optimal_values_lbl = metrics_df_lbl.loc[metrics_df_lbl[column_names[2]].idxmax()].values\n",
    "    best_tresholds.append(optimal_values_lbl[1])\n",
    "    best_scores.append(optimal_values_lbl[2])\n",
    "\n",
    "  if print_score:\n",
    "    for index, label in enumerate(label_columns):\n",
    "      print('%s treshold=%.2f Score=%.3f' % (label, best_tresholds[index], best_scores[index]))\n",
    "\n",
    "  return best_tresholds\n",
    "\n",
    "def segmentation_tunning(model, target_df, df, df_images_dest_path, label_columns, mask_grid, threshold_grid=np.arange(0, 1, .01), N_CLASSES=4, preprocessing=None, adjust_fn=None, adjust_param=None, seed=0, column_names=['Class', 'Threshold', 'Mask size', 'Dice'], print_score=True):\n",
    "    metrics = []\n",
    "\n",
    "    for label in label_columns:\n",
    "        for threshold in threshold_grid:\n",
    "            for mask_size in mask_grid:\n",
    "                metrics.append([label, threshold, mask_size, 0])\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics, columns=column_names)\n",
    "\n",
    "    for i in range(0, df.shape[0], 500):\n",
    "        batch_idx = list(range(i, min(df.shape[0], i + 500)))\n",
    "        batch_set = df[batch_idx[0]: batch_idx[-1]+1]\n",
    "        ratio = len(batch_set) / len(df)\n",
    "\n",
    "        generator = DataGenerator(\n",
    "                      directory=df_images_dest_path,\n",
    "                      dataframe=batch_set,\n",
    "                      target_df=target_df,\n",
    "                      batch_size=len(batch_set), \n",
    "                      target_size=model.input_shape[1:3],\n",
    "                      n_channels=model.input_shape[3],\n",
    "                      n_classes=N_CLASSES,\n",
    "                      preprocessing=preprocessing,\n",
    "                      adjust_fn=adjust_fn,\n",
    "                      adjust_param=adjust_param,\n",
    "                      seed=seed,\n",
    "                      mode='fit',\n",
    "                      shuffle=False)\n",
    "\n",
    "        x, y = generator.__getitem__(0)\n",
    "        preds = model.predict(x)\n",
    "\n",
    "        for class_index, label in enumerate(label_columns):\n",
    "            class_score = []\n",
    "            label_class = y[..., class_index]\n",
    "            pred_class = preds[..., class_index]\n",
    "            for threshold in threshold_grid:\n",
    "                for mask_size in mask_grid:\n",
    "                    mask_score = []\n",
    "                    for index in range(len(batch_idx)):\n",
    "                        label_mask = label_class[index, ]\n",
    "                        pred_mask = pred_class[index, ]\n",
    "                        pred_mask = post_process(pred_mask, threshold=threshold, min_size=mask_size)\n",
    "                        dice_score = dice_coefficient(pred_mask, label_mask)\n",
    "                        if (pred_mask.sum() == 0) & (label_mask.sum() == 0):\n",
    "                            dice_score = 1.\n",
    "                        mask_score.append(dice_score)\n",
    "                    metrics_df.loc[(metrics_df[column_names[0]] == label) & (metrics_df[column_names[1]] == threshold) & \n",
    "                                   (metrics_df[column_names[2]] == mask_size), column_names[3]] += np.mean(mask_score) * ratio\n",
    "                    \n",
    "    best_tresholds = []\n",
    "    best_masks = []\n",
    "    best_dices = []\n",
    "    for index, label in enumerate(label_columns):\n",
    "        metrics_df_lbl = metrics_df[metrics_df[column_names[0]] == label_columns[index]]\n",
    "        optimal_values_lbl = metrics_df_lbl.loc[metrics_df_lbl[column_names[3]].idxmax()].values\n",
    "        best_tresholds.append(optimal_values_lbl[1])\n",
    "        best_masks.append(optimal_values_lbl[2])\n",
    "        best_dices.append(optimal_values_lbl[3])\n",
    "\n",
    "    if print_score:\n",
    "        for index, name in enumerate(label_columns):\n",
    "            print('%s treshold=%.2f mask size=%d Dice=%.3f' % (name, best_tresholds[index], best_masks[index], best_dices[index]))\n",
    "            \n",
    "    return best_tresholds, best_masks\n",
    "\n",
    "# Model utils\n",
    "def ensemble_models(input_shape, model_list):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    outputs = average([model(inputs) for model in model_list])\n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Data generator\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, dataframe, directory, batch_size, n_channels, target_size,  n_classes, \n",
    "                 mode='fit', target_df=None, shuffle=True, preprocessing=None, augmentation=None, adjust_fn=None, adjust_param=None, seed=0):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.dataframe = dataframe\n",
    "        self.mode = mode\n",
    "        self.directory = directory\n",
    "        self.target_df = target_df\n",
    "        self.target_size = target_size\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.preprocessing = preprocessing\n",
    "        self.augmentation = augmentation\n",
    "        self.adjust_fn = adjust_fn\n",
    "        self.adjust_param = adjust_param\n",
    "        self.seed = seed\n",
    "        self.mask_shape = (1400, 2100)\n",
    "        self.list_IDs = self.dataframe.index\n",
    "        \n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n",
    "        X = self.__generate_X(list_IDs_batch)\n",
    "        \n",
    "        if self.mode == 'fit':\n",
    "            Y = self.__generate_Y(list_IDs_batch)\n",
    "            \n",
    "            if self.augmentation:\n",
    "                X, Y = self.__augment_batch(X, Y)\n",
    "            \n",
    "            return X, Y\n",
    "        \n",
    "        elif self.mode == 'predict':\n",
    "            return X\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __generate_X(self, list_IDs_batch):\n",
    "        X = np.empty((self.batch_size, *self.target_size, self.n_channels))\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            img_name = self.dataframe['image'].loc[ID]\n",
    "            img_path = self.directory + img_name\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if (not self.adjust_fn is None) & (not self.adjust_param is None):\n",
    "                img = self.adjust_fn(img, self.adjust_param)\n",
    "\n",
    "            if self.preprocessing:\n",
    "                img = self.preprocessing(img)\n",
    "                \n",
    "            X[i,] = img\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def __generate_Y(self, list_IDs_batch):\n",
    "        Y = np.empty((self.batch_size, *self.target_size, self.n_classes), dtype=int)\n",
    "        \n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            img_name = self.dataframe['image'].loc[ID]\n",
    "            image_df = self.target_df[self.target_df['image'] == img_name]\n",
    "            rles = image_df['EncodedPixels'].values\n",
    "            masks = build_masks(rles, input_shape=self.mask_shape, reshape=self.target_size)\n",
    "            Y[i, ] = masks\n",
    "\n",
    "        return Y\n",
    "    \n",
    "    def __augment_batch(self, X_batch, Y_batch):\n",
    "        for i in range(X_batch.shape[0]):\n",
    "            X_batch[i, ], Y_batch[i, ] = self.__random_transform(X_batch[i, ], Y_batch[i, ])\n",
    "        \n",
    "        return X_batch, Y_batch\n",
    "    \n",
    "    def __random_transform(self, X, Y):\n",
    "        composed = self.augmentation(image=X, mask=Y)\n",
    "        X_aug = composed['image']\n",
    "        Y_aug = composed['mask']\n",
    "        \n",
    "        return X_aug, Y_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "seed_everything(seed)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCVDcAP0Hq0P"
   },
   "outputs": [],
   "source": [
    "train_path = '../data/train.csv'\n",
    "hold_out_set_path = '../data/hold-out.csv'\n",
    "train_images_path = '../data/train_images384x480/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SnKKLczHdqn"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 69645,
     "status": "ok",
     "timestamp": 1570466015936,
     "user": {
      "displayName": "Dimitre Oliveira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBHzrYFhikwGj5HS4HCH2B5iUmYoPpm1AFV6OcFBA=s64",
      "userId": "06256612867315483887"
     },
     "user_tz": 180
    },
    "id": "pH6kKJKoHdqo",
    "outputId": "8487a872-6af4-446e-ff73-0d0c01c50571"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compete set samples: 22184\n",
      "Train samples:  4420\n",
      "Validation samples:  1105\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>Fish_mask</th>\n",
       "      <th>Flower_mask</th>\n",
       "      <th>Gravel_mask</th>\n",
       "      <th>Sugar_mask</th>\n",
       "      <th>Fish</th>\n",
       "      <th>Flower</th>\n",
       "      <th>Gravel</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66cda54.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18208 624 19608 624 21008 624 22408 624 23808 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61d6640.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1349079 387 1350479 387 1351879 387 1353279 38...</td>\n",
       "      <td>373839 334 375239 334 376639 334 378039 334 37...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bb31239.jpg</td>\n",
       "      <td>29 604 1429 604 2829 604 4229 604 5629 604 702...</td>\n",
       "      <td>1692065 510 1693465 510 1694865 510 1696265 51...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74d06fc.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1435419 454 1436819 454 1438219 454 1439619 45...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f13cbe0.jpg</td>\n",
       "      <td>330457 1020 331857 1020 333257 1020 334657 102...</td>\n",
       "      <td>390661 1208 392061 1208 393461 1208 394861 120...</td>\n",
       "      <td>1629705 16 1629722 1144 1631105 16 1631122 4 1...</td>\n",
       "      <td>2561203 314 2562603 314 2564003 314 2565403 31...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image                                          Fish_mask  \\\n",
       "0  66cda54.jpg                                                NaN   \n",
       "1  61d6640.jpg                                                NaN   \n",
       "2  bb31239.jpg  29 604 1429 604 2829 604 4229 604 5629 604 702...   \n",
       "3  74d06fc.jpg                                                NaN   \n",
       "4  f13cbe0.jpg  330457 1020 331857 1020 333257 1020 334657 102...   \n",
       "\n",
       "                                         Flower_mask  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  1692065 510 1693465 510 1694865 510 1696265 51...   \n",
       "3                                                NaN   \n",
       "4  390661 1208 392061 1208 393461 1208 394861 120...   \n",
       "\n",
       "                                         Gravel_mask  \\\n",
       "0                                                NaN   \n",
       "1  1349079 387 1350479 387 1351879 387 1353279 38...   \n",
       "2                                                NaN   \n",
       "3  1435419 454 1436819 454 1438219 454 1439619 45...   \n",
       "4  1629705 16 1629722 1144 1631105 16 1631122 4 1...   \n",
       "\n",
       "                                          Sugar_mask  Fish  Flower  Gravel  \\\n",
       "0  18208 624 19608 624 21008 624 22408 624 23808 ...     0       0       0   \n",
       "1  373839 334 375239 334 376639 334 378039 334 37...     0       0       1   \n",
       "2                                                NaN     1       1       0   \n",
       "3                                                NaN     0       0       1   \n",
       "4  2561203 314 2562603 314 2564003 314 2565403 31...     1       1       1   \n",
       "\n",
       "   Sugar    set  \n",
       "0      1  train  \n",
       "1      1  train  \n",
       "2      0  train  \n",
       "3      0  train  \n",
       "4      1  train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "hold_out_set = pd.read_csv(hold_out_set_path)\n",
    "\n",
    "X_train = hold_out_set[hold_out_set['set'] == 'train']\n",
    "X_val = hold_out_set[hold_out_set['set'] == 'validation']\n",
    "\n",
    "print('Compete set samples:', len(train))\n",
    "print('Train samples: ', len(X_train))\n",
    "print('Validation samples: ', len(X_val))\n",
    "\n",
    "# Preprocecss data\n",
    "train['image'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "display(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xyPzEBHGHdqr"
   },
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BBNl0qkSHdqs"
   },
   "outputs": [],
   "source": [
    "N_GPUS = 3\n",
    "BACKBONE = 'densenet169'\n",
    "BATCH_SIZE = 8 * N_GPUS\n",
    "EPOCHS = 40\n",
    "LEARNING_RATE = 1e-3\n",
    "HEIGHT = 384\n",
    "WIDTH = 480\n",
    "CHANNELS = 3\n",
    "N_CLASSES = 4\n",
    "ES_PATIENCE = 5\n",
    "RLROP_PATIENCE = 3\n",
    "DECAY_DROP = 0.2\n",
    "ADJUST_FN = exposure.adjust_gamma\n",
    "ADJUST_PARAM = 0.8\n",
    "\n",
    "model_uNet_path = 'files/uNet_%s_%sx%s.h5' % (BACKBONE, HEIGHT, WIDTH)\n",
    "model_linkNet_path = 'files/linkNet_%s_%sx%s.h5' % (BACKBONE, HEIGHT, WIDTH)\n",
    "model_pspNet_path = 'files/pspNet_%s_%sx%s.h5' % (BACKBONE, HEIGHT, WIDTH)\n",
    "model_fpnNet_path = 'files/fpnNet_%s_%sx%s.h5' % (BACKBONE, HEIGHT, WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": false,
    "colab": {},
    "colab_type": "code",
    "hide_input": true,
    "id": "YXFIjNcKHdqv"
   },
   "outputs": [],
   "source": [
    "preprocessing = sm.backbones.get_preprocessing(BACKBONE)\n",
    "\n",
    "augmentation = albu.Compose([albu.HorizontalFlip(p=0.5),\n",
    "                             albu.VerticalFlip(p=0.5),\n",
    "                             albu.GridDistortion(p=0.5),\n",
    "                             albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, \n",
    "                                                   shift_limit=0.1, border_mode=0, p=0.5)\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vaGBD0NAHdq7"
   },
   "source": [
    "### Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "hide_input": true,
    "id": "yYQxaJVLHdq8"
   },
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(\n",
    "                  directory=train_images_path,\n",
    "                  dataframe=X_train,\n",
    "                  target_df=train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  target_size=(HEIGHT, WIDTH),\n",
    "                  n_channels=CHANNELS,\n",
    "                  n_classes=N_CLASSES,\n",
    "                  preprocessing=preprocessing,\n",
    "                  augmentation=augmentation,\n",
    "                  adjust_fn=ADJUST_FN,\n",
    "                  adjust_param=ADJUST_PARAM,\n",
    "                  seed=seed)\n",
    "\n",
    "valid_generator = DataGenerator(\n",
    "                  directory=train_images_path,\n",
    "                  dataframe=X_val,\n",
    "                  target_df=train,\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  target_size=(HEIGHT, WIDTH),\n",
    "                  n_channels=CHANNELS,\n",
    "                  n_classes=N_CLASSES,\n",
    "                  preprocessing=preprocessing,\n",
    "                  adjust_fn=ADJUST_FN,\n",
    "                  adjust_param=ADJUST_PARAM,\n",
    "                  seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Idm7ex1GHdq_"
   },
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "colab": {},
    "colab_type": "code",
    "id": "OqorBKOuHdrA"
   },
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "model_s = sm.Unet(backbone_name=BACKBONE, \n",
    "                  encoder_weights='imagenet',\n",
    "                  classes=N_CLASSES,\n",
    "                  activation='sigmoid',\n",
    "                  input_shape=(HEIGHT, WIDTH, CHANNELS))\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_uNet_path, monitor='val_loss', mode='min', save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\n",
    "rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLROP_PATIENCE, factor=DECAY_DROP, min_lr=1e-6, verbose=1)\n",
    "\n",
    "metric_list = [dice_coef, sm.metrics.iou_score, sm.metrics.f1_score]\n",
    "callback_list = [checkpoint, es, rlrop]\n",
    "optimizer = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)\n",
    "\n",
    "model = multi_gpu_model(model_s, gpus=N_GPUS)\n",
    "model.compile(optimizer=optimizer, loss=sm.losses.bce_dice_loss, metrics=metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2870022,
     "status": "ok",
     "timestamp": 1570484328594,
     "user": {
      "displayName": "Dimitre Oliveira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBHzrYFhikwGj5HS4HCH2B5iUmYoPpm1AFV6OcFBA=s64",
      "userId": "06256612867315483887"
     },
     "user_tz": 180
    },
    "id": "bD00H9izHdrD",
    "outputId": "ac06e686-c8ed-49e5-ab38-cd127fd6bf9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "184/184 [==============================] - 1057s 6s/step - loss: 1.3295 - dice_coef: 0.2914 - iou_score: 0.1286 - score: 0.1977 - val_loss: 1.4300 - val_dice_coef: 0.3419 - val_iou_score: 0.1610 - val_score: 0.2349\n",
      "Epoch 2/40\n",
      "184/184 [==============================] - 848s 5s/step - loss: 1.0938 - dice_coef: 0.3927 - iou_score: 0.1600 - score: 0.2342 - val_loss: 1.2994 - val_dice_coef: 0.3997 - val_iou_score: 0.1619 - val_score: 0.2317\n",
      "Epoch 3/40\n",
      "184/184 [==============================] - 847s 5s/step - loss: 1.0512 - dice_coef: 0.4319 - iou_score: 0.1725 - score: 0.2470 - val_loss: 1.2125 - val_dice_coef: 0.4525 - val_iou_score: 0.1913 - val_score: 0.2646\n",
      "Epoch 4/40\n",
      "184/184 [==============================] - 844s 5s/step - loss: 1.0455 - dice_coef: 0.4416 - iou_score: 0.1758 - score: 0.2507 - val_loss: 1.4109 - val_dice_coef: 0.4543 - val_iou_score: 0.2088 - val_score: 0.2823\n",
      "Epoch 5/40\n",
      "184/184 [==============================] - 841s 5s/step - loss: 1.0407 - dice_coef: 0.4480 - iou_score: 0.1786 - score: 0.2533 - val_loss: 1.1549 - val_dice_coef: 0.4995 - val_iou_score: 0.2080 - val_score: 0.2816\n",
      "Epoch 6/40\n",
      "184/184 [==============================] - 845s 5s/step - loss: 1.0345 - dice_coef: 0.4524 - iou_score: 0.1814 - score: 0.2565 - val_loss: 1.1700 - val_dice_coef: 0.4358 - val_iou_score: 0.1790 - val_score: 0.2526\n",
      "Epoch 7/40\n",
      "184/184 [==============================] - 850s 5s/step - loss: 1.0299 - dice_coef: 0.4564 - iou_score: 0.1838 - score: 0.2591 - val_loss: 1.0548 - val_dice_coef: 0.5030 - val_iou_score: 0.2125 - val_score: 0.2877\n",
      "Epoch 8/40\n",
      "184/184 [==============================] - 859s 5s/step - loss: 1.0248 - dice_coef: 0.4621 - iou_score: 0.1859 - score: 0.2611 - val_loss: 1.2078 - val_dice_coef: 0.4577 - val_iou_score: 0.1892 - val_score: 0.2601\n",
      "Epoch 9/40\n",
      " 26/184 [===>..........................] - ETA: 7:05 - loss: 1.0171 - dice_coef: 0.4622 - iou_score: 0.1900 - score: 0.2667"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN = len(X_train)//BATCH_SIZE\n",
    "STEP_SIZE_VALID = len(X_val)//BATCH_SIZE\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                              validation_data=valid_generator,\n",
    "                              validation_steps=STEP_SIZE_VALID,\n",
    "                              callbacks=callback_list,\n",
    "                              epochs=EPOCHS,\n",
    "                              verbose=1).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0-PPEeGGHdrG"
   },
   "source": [
    "## Model loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 948
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2852741,
     "status": "ok",
     "timestamp": 1570484330891,
     "user": {
      "displayName": "Dimitre Oliveira",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBHzrYFhikwGj5HS4HCH2B5iUmYoPpm1AFV6OcFBA=s64",
      "userId": "06256612867315483887"
     },
     "user_tz": 180
    },
    "hide_input": false,
    "id": "F1uV9E1RHdrH",
    "outputId": "79ffb470-d1fe-4b8e-f2d0-dc02c4c33c7c"
   },
   "outputs": [],
   "source": [
    "plot_metrics(history, metric_list=['loss', 'dice_coef', 'iou_score', 'score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s = sm.Linknet(backbone_name=BACKBONE, \n",
    "                      encoder_weights='imagenet',\n",
    "                      classes=N_CLASSES,\n",
    "                      activation='sigmoid',\n",
    "                      input_shape=(HEIGHT, WIDTH, CHANNELS))\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_linkNet_path, monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "callback_list = [checkpoint, es, rlrop]\n",
    "optimizer = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)\n",
    "\n",
    "model = multi_gpu_model(model_s, gpus=N_GPUS)\n",
    "model.compile(optimizer=optimizer, loss=sm.losses.bce_dice_loss, metrics=metric_list)\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                              validation_data=valid_generator,\n",
    "                              validation_steps=STEP_SIZE_VALID,\n",
    "                              callbacks=callback_list,\n",
    "                              epochs=EPOCHS,\n",
    "                              verbose=1).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history, metric_list=['loss', 'dice_coef', 'iou_score', 'score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSP-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s = sm.PSPNet(backbone_name=BACKBONE, \n",
    "                      encoder_weights='imagenet',\n",
    "                      classes=N_CLASSES,\n",
    "                      activation='sigmoid',\n",
    "                      input_shape=(HEIGHT, WIDTH, CHANNELS))\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_pspNet_path, monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "callback_list = [checkpoint, es, rlrop]\n",
    "optimizer = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)\n",
    "\n",
    "model = multi_gpu_model(model_s, gpus=N_GPUS)\n",
    "model.compile(optimizer=optimizer, loss=sm.losses.bce_dice_loss, metrics=metric_list)\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                              validation_data=valid_generator,\n",
    "                              validation_steps=STEP_SIZE_VALID,\n",
    "                              callbacks=callback_list,\n",
    "                              epochs=EPOCHS,\n",
    "                              verbose=1).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history, metric_list=['loss', 'dice_coef', 'iou_score', 'score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s = sm.FPN(backbone_name=BACKBONE, \n",
    "                  encoder_weights='imagenet',\n",
    "                  classes=N_CLASSES,\n",
    "                  activation='sigmoid',\n",
    "                  input_shape=(HEIGHT, WIDTH, CHANNELS))\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_fpnNet_path, monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "callback_list = [checkpoint, es, rlrop]\n",
    "optimizer = RAdam(learning_rate=LEARNING_RATE, warmup_proportion=0.1)\n",
    "\n",
    "model = multi_gpu_model(model_s, gpus=N_GPUS)\n",
    "model.compile(optimizer=optimizer, loss=sm.losses.bce_dice_loss, metrics=metric_list)\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                              validation_data=valid_generator,\n",
    "                              validation_steps=STEP_SIZE_VALID,\n",
    "                              callbacks=callback_list,\n",
    "                              epochs=EPOCHS,\n",
    "                              verbose=1).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history, metric_list=['loss', 'dice_coef', 'iou_score', 'score'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "36-linknet-densenet169.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
